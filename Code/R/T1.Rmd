---
title: "T1"
author: "Carlos Beltrán López"
date: "2023-03-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(MASS)
library(dplyr)
library(tidyr)
library(stringr)
library(rjson)
library(nnet)
library(graphics)
library(normalr)
```

Función análisis
```{r}
# Function to compute the correct statistical test based on types of variables (categorical or numerical)
# Input: 
#       formula: expressi?n with dependences of class formula (in R format)
#       data: dataframe with patient data
myAssoc2 <- function(formula, data, exclude = NA, fig = TRUE) {
  vars <- all.vars(formula)
  y <- data[,vars[1]]
  ny <- vars[1]
  x <- data[,vars[2]]
  nx <- vars[2]
  # Remove missing data
  data <- na.omit(data[,c(vars[1], vars[2])])
  # Check if categorical or continuos variables
  # ------
  # Both categorical variables
  if (is.factor(y) & is.factor(x)) {
    ctab <- xtabs(as.formula(paste("~", ny ,"+", nx)), data = data, exclude = exclude)
    if (any(ctab <= 5)) {
      # The number of observations in the contingency table does not fall into the range in which the asymptotic chi-square 
      # approximation is valid. One means of overcoming this problem is to use a Monte Carlo simulation 
      # (argument simulated.p.value = TRUE), in which contingency tables are generated whose entries are set of random numbers 
      # such that their values add up to the marginal values of the contingency table being tested and the fraction of the 
      # tables whose chi-squared statistic is more extreme is recorded.
      test <- "Chi-squared Monte Carlo sim"
      pval.chisMC <- chisq.test(ctab, simulate.p.value = T)$p.value
      # An alternative method, Fisher's exact test, relies on the fact that, under the assumption of independence of X and Y 
      # and for fixed marginal values, the elements of the contingency table are distributed according to a hypergeometric 
      # probability distribution.
      # if (fisher) {
        test <- "Fisher"
        # Exception management by using "try""
        pval.ok <- try(fisher.test(ctab, workspace = 2e+07)$p.value, silent = TRUE)
        if (class(pval.ok) ==  "try-error") {
          # if error with Fisher test, returns chi-q Monte Carlo results
          test <- "Chi-squared Monte Carlo sim"
          pvalue <- pval.chisMC
        }
        else pvalue <- pval.ok
      # }
      # res <- list(ctab = ctab, test = test, pvalue = pvalue, pval.chisMC = pval.chisMC, oddr = oddsratio(ctab)$measure["TRUE",])
      res <- list(ctab = ctab, test = test, pvalue = pvalue, pval.chisMC = pval.chisMC)
    }
    else {
      test <- "Chi-squared"; pvalue <- chisq.test(ctab)$p.value
      # res <- list(ctab = ctab, test = test, pvalue = pvalue, oddr = oddsratio(ctab)$measure["TRUE",])
      res <- list(ctab = ctab, test = test, pvalue = pvalue)
    }
    if (fig) {par(mfrow = c(1,1)); barplot(ctab, legend = TRUE, beside = TRUE, xlab = nx, ylab = ny, 
                                           main = paste(ny, " vs ", nx, " (", test, " pvalue = ", ifelse(is.na(pvalue), round(pval.chisMC, 5), round(pvalue, 5)), ")", sep = ""))}        
  }
  # -----
  # Both numerical variables
  else if (is.numeric(y) & is.numeric(x)) {
    # If the samples follow independent normal distributions
    if ((shapiro.test(x)$p.value > 0.05) & (shapiro.test(y)$p.value > 0.05)) {
      # The test statistic is based on Pearson's product moment correlation coefficient cor(x, y) and follows a t distribution 
      test <- "Pearson correlation"
      cor.test(y, x, alternative="two.sided", method="pearson")
    }
    # If the data do not necessarily come from a bivariate normal distribution
    else {
      # Kendall's tau or Spearman's rho statistic is used to estimate a rank-based measure of association
      # Spearmann when variable are both continuos
      test <- "Spearmann's rho statistic"
      pvalue <- cor.test(y, x, alternative="two.sided", method="spearman")$p.value
      # Kendall when any of variables are ordinal
    }
    res <- list(test.norm = (shapiro.test(x)$p.value > 0.05) & (shapiro.test(y)$p.value > 0.05), test = test, pvalue = pvalue)
    if (fig) {par(mfrow = c(1,1)); plot(x, y, xlab = nx, ylab = ny, 
                                        main = paste(ny, " vs ", nx, " (", test, " pvalue = ", round(pvalue, 5), ")", sep = ""))}    
  }
  # -----
  # Categorical and numerical variables
  else {
    # Swap x and y
    if (is.factor(x)) {x <- data[,vars[1]]; nx <- vars[1]; y <- data[,vars[2]]; ny <- vars[2]}
    if (shapiro.test(x)$p.value <= 0.05) { 
      # Compute median for categories (not mean, it?s not normal distribution)
      mean.med <- tapply(x, y, median, na.rm=TRUE)
      if (nlevels(y) > 2) {
        # Not normal distribution. 
        test <- "Kruskal-Wallis"
        # kruskal.test performs a Kruskal-Wallis rank sum test of the null that the location parameters of the distribution 
        # x are the same in each group (sample). The alternative is that they differ in at least one.
        # The Wilcoxon rank sum test (wilcox.test) as the special case for two samples.
        pvalue <- kruskal.test(as.formula(paste(nx, "~", ny)), data = data)$p.value
        # Other way: Compute multinom models
        modelo0 <- multinom(as.formula(paste(ny, "~ 1")), data = data, trace = F)
        modelo1 <- multinom(as.formula(paste(ny, "~", nx)), data = data, trace = F)
        pval.mult <- anova(modelo0, modelo1)[2,"Pr(Chi)"]
        res <- list(test.norm = shapiro.test(x), mean.med = mean.med, test = test, pvalue = pvalue, pval.mult = pval.mult)
      } else {
        test <- "Wilcoxon rank sum" # Mann-Whitney test
        pvalue <- wilcox.test(as.formula(paste(nx, "~", ny)), data = data)$p.value
        pval.glm <- summary(glm(as.formula(paste(ny, "~", nx)), data = data, 
                              family=binomial("logit")))$coefficients[2,"Pr(>|z|)"] 
        res <- list(test.norm = shapiro.test(x), mean.med = mean.med, test = test, pvalue = pvalue, pval.glm = pval.glm)
      }
    } else {
      # Not normal distribution. 
      test <- "Student's t test"
      # lm together with anova for performing one-way location analysis under normality assumptions.
      # Student's t test (t.test) as the special case for two samples
      mean.m <- tapply(x, y, mean, na.rm=TRUE)
      pvalue <- t.test(as.formula(paste(nx, "~", ny)), data = data)$p.value
      pval.aov <- unlist(summary(aov(as.formula(paste(nx, "~", ny)), data = data)))["Pr(>F)1"]
      res <- list(test.norm = shapiro.test(x), mean.med = mean.m, test = test, pvalue = pvalue, pval.aov = pval.aov)
    }
    if (fig) {par(mfrow = c(1,1)); boxplot(as.formula(paste(nx, "~", ny)), data = data, id.method="y",
                                           main = paste(ny, " vs ", nx, " (", test, " pvalue = ", round(pvalue, 5), ")", sep = ""))}
  }
  return (res)
}
```

```{r}
data.json <- fromJSON(file="datoshistorias.JSON")
pacientes.json <- data.json[["pacientes"]]
```

```{r}
#Procesando todas las variables que nos interesan convirtiendolas en vectores para más tarde hacer un dataframe.

nombres <- lapply(pacientes.json, function(x) x["nombre"])
nombres <- lapply(nombres, function(x) x$nombre)
nombres[sapply(nombres, is.null)] <- NA #cambiando NULL por NA para evitar que las funciones hagan drop de esos valores.
nombres <- unlist(nombres, use.names = FALSE)

apellidos <- lapply(pacientes.json, function(x) x["apellidos"])
apellidos <- lapply(apellidos, function(x) x$apellidos)
apellidos[sapply(apellidos, is.null)] <- NA 
apellidos <- unlist(apellidos, use.names = FALSE)

dni <- lapply(pacientes.json, function(x) x["dni"])
dni <- lapply(dni, function(x) x$dni)
dni[sapply(dni, is.null)] <- NA
dni <- unlist(dni, use.names = FALSE)

fechaNacimiento <- lapply(pacientes.json, function(x) x["fechaNacimiento"])
fechaNacimiento <- lapply(fechaNacimiento, function(x) x$fechaNacimiento)
fechaNacimiento[sapply(fechaNacimiento, is.null)] <- NA
fechaNacimiento <- unlist(fechaNacimiento, use.names = FALSE)
```

```{r}
#Creo un vector con las historias de los pacientes.
historia <- lapply(pacientes.json, function(x) x[["camposPersonalizados"]])

historia <- lapply(historia, function(x) 
  if (length(x)>0){
    j=0
    for (i in 1:length(x)){ #Accedo a cada paciente y busco el campo personalizado "Historia".
      if (x[[i]][["campo"]]=="Historia"){
        j=i
      }
    }
    if (j==0){NULL} #Si no hay Historia escribo un NULL
    else{
    gsub("<.*?>", "", x[[j]][["valor"]])} #uso gsub para eliminar los tags de html que hay en las historias
    }
  else{
    NULL
    }
  )


historia[sapply(historia, is.null)] <- NA #cambio NULLs por NA
histdf <- data.frame("Historial"=matrix(historia)) #lo hago primero matriz para que no se hagan miles de variables, si no miles de muestras con una variable.

```

```{r}

pacientesHistoria <- data.frame("Nombre"=nombres, "Apellidos"=apellidos, "FechaNac"=fechaNacimiento,"DNI"=dni, "Historial"=histdf)

pacientesHistoria <- data.frame(apply(pacientesHistoria,2,as.character)) #Historial me daba problemas por el formato lista, todo proviene del tipo LargeList, con esto lo soluciono.

#Quito las tildes
pacientesHistoria$Nombre <- iconv(pacientesHistoria$Nombre, from="UTF-8", to = "ASCII//TRANSLIT")
pacientesHistoria$Apellidos <- iconv(pacientesHistoria$Apellidos, from="UTF-8", to = "ASCII//TRANSLIT")
pacientesHistoria$Historial <- iconv(pacientesHistoria$Historial, from="UTF-8", to = "ASCII//TRANSLIT")

#Elimino los pacientes que no tengan historial grabado
pacientesHistoria <- subset(pacientesHistoria,!(is.na(pacientesHistoria$Historial) | pacientesHistoria$Historial == 'NA') )
pacientesHistoria <- subset(pacientesHistoria, select = c(-FechaNac,-DNI)) #Quito Fecha de Nacimiento y DNI que no los necesitamos
write.csv2(pacientesHistoria,"pacientesHistoria.csv")
```
PRIMERA BASE DE DATOS HECHA EN CSV.

```{r}
historias <- read.table("pacientesHistoria.csv",sep=";",dec=",",header = T, stringsAsFactors = T, na.strings = "NA")
historias <- subset(historias, select = -1)
```

¿Cuántos pacientes hay de cada etiqueta en la base de datos de historias?
```{r}
historias <- historias %>%
  mutate(Patology = case_when(
    grepl("fasc",historias$Historial,ignore.case=TRUE) ~ "Fascitis",
    grepl( "esguince",historias$Historial,ignore.case=TRUE) ~ "Esguince",
    grepl( "pie plano|plano|PP",historias$Historial,ignore.case=TRUE) ~ "Pie Plano",
    grepl( "pie cavo|cavo|PC|vavo",historias$Historial,ignore.case=TRUE) ~ "Pie Cavo",
    grepl( "aquiles|aquilea",historias$Historial,ignore.case=TRUE) ~ "Aquiles",
    grepl( "predislocacion|pred|Sind",historias$Historial,ignore.case=TRUE) ~ "Predislocación",
    TRUE ~ "otro"
  ), .before = 1)

v <- historias[which(historias$Patology=="Predislocación"),]
summary(as.factor(historias$Patology))
```

```{r}
pesos <- read.table("Pesos.csv",sep=";", header=T,stringsAsFactors = T)
pesos <- pesos[1:5]
colnames(pesos) <- c("Nombre", "Apellidos", "Peso(Kg)", "Altura(cm)", "N.Pie")
pesos$`Peso(Kg)`<- gsub(" Kg","",pesos$`Peso(Kg)`)
pesos$`Peso(Kg)`<- gsub(",",".",pesos$`Peso(Kg)`)
pesos$`Altura(cm)`<- gsub(" cm","",pesos$`Altura(cm)`)
pesos$`N.Pie`<- gsub(",",".",pesos$`N.Pie`)
pesos$`Peso(Kg)` <- as.numeric(pesos$`Peso(Kg)`)
pesos$`Altura(cm)` <- as.numeric(pesos$`Altura(cm)`)
pesos$`N.Pie` <- as.numeric(pesos$`N.Pie`)
```

```{r}
#Borro las entradas que tenga el nombre nulo o los tres datos a la vez nulos. 
pesos <- subset(pesos,!(is.na(pesos$Nombre) | (is.na(pesos$`Peso(Kg)`) & is.na(pesos$`Altura(cm)`) & is.na(pesos$`N.Pie`) ) ) )

#Quito las tildes
pesos$Nombre <- iconv(pesos$Nombre, from="UTF-8", to = "ASCII//TRANSLIT")
pesos$Apellidos <- iconv(pesos$Apellidos, from="UTF-8", to = "ASCII//TRANSLIT")

#Borro duplicados
pesos <- subset(pesos, !duplicated(paste(pesos$Nombre,pesos$Apellidos)))

write.csv2(pesos, "PesoAlturaPie.csv")
```

SEGUNDA BASE DE DATOS HECHA EN CSV. (PESO, ALTURA Y NUMERO DE PIE)

```{r}
pesos <- read.table("PesoAlturaPie.csv",sep=";",dec=",",header = T, stringsAsFactors = T)[-1]
```

MERGE DE AMBOS DATA FRAMES

```{r}
#unión de solo los datos que coinciden de los dataframe, descartando los que no:
pacientesInnerJoin <- merge(historias, pesos, by = c('Nombre','Apellidos'))
#unión de ambos dataframes si coinciden; si no coinciden, solo se añaden aquellos provenientes del dataframe historial (puesto que tener historial es obligatorio para el entrenamiento del programa por lo que no nos sirven aquellos pacientes sin historial), es decir, guardamos los pacientes que no tenemos su peso, altura y nº de pie para poder trabajar con sus datos de opto
pacientesLeftJoin <-merge(historias, pesos, by = c('Nombre','Apellidos'), all.x=TRUE)

```

DF DE OPTOGAIT

```{r}
opto <- read.table("Optogait.csv", header=T, sep = ";",dec=",", fileEncoding= "latin1")

#crea un df con todos los registros de cada paciente unificados, sacando la media y la desviación típica

#Hago el dataframe que voy a unir al anterior para tener ya el dataset final.
opto <- mutate(opto,ApellidosyNombre = paste(opto$Apellidos, opto$Nombre))

# Calcular la media de todas las columnas para cada ApellidosyNombre

#Si uso data.table en vez de dataframe es más sencillo, simplente haciendo esto: opto[, sd(TContacto,na.rm=T), by="ApellidosyNombre"]


media_datos <- opto %>%
  group_by(ApellidosyNombre) %>%
  summarise(TContacto.media=mean(TContacto,na.rm=T), 
            TPaso.media=mean(TPaso,na.rm=T), 
            Ritmo.paso.media=mean(`Ritmo..paso.m.`,na.rm=T), 
            Paso.media=mean(Paso,na.rm=T), 
            Velocidad.media=mean(Velocidad,na.rm=T), 
            Aceleracion.media=mean(Aceleracion,na.rm=T), 
            Desequilibrio.media=mean(Desequilibrio,na.rm=T), 
            Distancia.media=mean(Distancia,na.rm=T), 
            Zancada.media=mean(Zancada,na.rm=T), 
            StrideTime.Cycle.media=mean(`StrideTime.Cycle`,na.rm=T), 
            SingleSupport.media=mean(SingleSupport,na.rm=T), 
            SingleSupport..media=mean(`SingleSupport.`,na.rm=T), 
            TotalDoubleSupport.media=mean(TotalDoubleSupport,na.rm=T), 
            TotalDoubleSupport..media=mean(`TotalDoubleSupport.`,na.rm=T), 
            TStance.media=mean(TStance,na.rm=T), 
            TStance..media=mean(`TStance.`,na.rm=T), 
            TSwing.media=mean(TSwing,na.rm=T), 
            TSwing..media=mean(`TSwing.`,na.rm=T), 
            ContactPhase.media=mean(ContactPhase,na.rm=T), 
            ContactPhase..media=mean(`ContactPhase.`,na.rm=T), 
            FootFlat.media=mean(FootFlat,na.rm=T), 
            FootFlat..media=mean(`FootFlat.`,na.rm=T), 
            PropulsivePhase.media=mean(`PropulsivePhase`,na.rm=T), 
            PropulsivePhase..media=mean(`PropulsivePhase.`,na.rm=T), 
            LoadResponse.media=mean(LoadResponse,na.rm=T), 
            LoadResponse..media=mean(`LoadResponse.`,na.rm=T), 
            PreSwing.media=mean(`PreSwing`,na.rm=T), 
            PreSwing..media=mean(`PreSwing.`,na.rm=T), 
            TContactoPerc.media=mean(TContactoPerc,na.rm=T))

# Calcular la desviación estándar de todas las columnas para cada ApellidosyNombre

desv_datos <- opto %>%
  group_by(ApellidosyNombre) %>%
  summarise(TContacto.desviacion=sd(TContacto,na.rm=T), 
            TPaso.desviacion=sd(TPaso,na.rm=T), 
            Ritmo.paso.desviacion=sd(`Ritmo..paso.m.`,na.rm=T), 
            Paso.desviacion=sd(Paso,na.rm=T), 
            Velocidad.desviacion=sd(Velocidad,na.rm=T), 
            Aceleracion.desviacion=sd(Aceleracion,na.rm=T), 
            Desequilibrio.desviacion=sd(Desequilibrio,na.rm=T), 
            Distancia.desviacion=sd(Distancia,na.rm=T), 
            Zancada.desviacion=sd(Zancada,na.rm=T), 
            StrideTime.Cycle.desviacion=sd(`StrideTime.Cycle`,na.rm=T), 
            SingleSupport.desviacion=sd(SingleSupport,na.rm=T), 
            SingleSupport..desviacion=sd(`SingleSupport.`,na.rm=T), 
            TotalDoubleSupport.desviacion=sd(TotalDoubleSupport,na.rm=T), 
            TotalDoubleSupport..desviacion=sd(`TotalDoubleSupport.`,na.rm=T), 
            TStance.desviacion=sd(TStance,na.rm=T), 
            TStance..desviacion=sd(`TStance.`,na.rm=T), 
            TSwing.desviacion=sd(TSwing,na.rm=T), 
            TSwing..desviacion=sd(`TSwing.`,na.rm=T), 
            ContactPhase.desviacion=sd(ContactPhase,na.rm=T), 
            ContactPhase..desviacion=sd(`ContactPhase.`,na.rm=T), 
            FootFlat.desviacion=sd(FootFlat,na.rm=T), 
            FootFlat..desviacion=sd(`FootFlat.`,na.rm=T), 
            PropulsivePhase.desviacion=sd(`PropulsivePhase`,na.rm=T), 
            PropulsivePhase..desviacion=sd(`PropulsivePhase.`,na.rm=T), 
            LoadResponse.desviacion=sd(LoadResponse,na.rm=T), 
            LoadResponse..desviacion=sd(`LoadResponse.`,na.rm=T), 
            PreSwing.desviacion=sd(`PreSwing`,na.rm=T), 
            PreSwing..desviacion=sd(`PreSwing.`,na.rm=T), 
            TContactoPerc.desviacion=sd(TContactoPerc,na.rm=T))

# Unir los resultados
nuevo_datos <- merge(media_datos, desv_datos, by = "ApellidosyNombre", suffixes = c(".media", ".desviacion"))

#De todos los datos nulos que hay, 55 son porque no se recogieron datos en esa prueba de optogait, es decir, una prueba vacía. Las eliminamos:
nuevo_datos <- subset(nuevo_datos,!is.na(nuevo_datos$TContacto.media))

# Borro las tildes de los nombres (para evitar futuras pérdidas de pacientes al fusionar los dataframes)
nuevo_datos$ApellidosyNombre <- iconv(nuevo_datos$ApellidosyNombre, from="UTF-8", to = "ASCII//TRANSLIT")

# Quito los espacios de los nombres y me quedo sólo con las tres primeras letras de cada nombre y apellidos para minimizar la cantidad de pacientes perdidos
# por ejemplo: Marta García Fernández -> margarfer

nuevo_datos$ApellidosyNombre <- lapply(nuevo_datos$ApellidosyNombre, function(x){ 
    name <- ""
    for (word in strsplit(x,split = " ")[[1]]){
      name <- paste0(name,substr(word,start=1,stop=3))
    }
    x <- name}
)
nuevo_datos$ApellidosyNombre <- gsub(" ","",nuevo_datos$ApellidosyNombre)

#Tenemos un DF con la media y la desviación típica de cada variable.
``` 


```{r}
#Junto las variables Nombre y Apellidos del anterior dataframe para poder unificarlo con el df de opto, le quito los espacios y me quedo con las tres primeras letras
pacientesInnerJoin <- mutate(pacientesInnerJoin,ApellidosyNombre = paste(pacientesInnerJoin$Apellidos, pacientesInnerJoin$Nombre))[-c(1,2)]
pacientesInnerJoin$ApellidosyNombre <- lapply(pacientesInnerJoin$ApellidosyNombre, function(x){ 
    name <- ""
    for (word in strsplit(x,split = " ")[[1]]){
      name <- paste0(name,substr(word,start=1,stop=3))
    }
    x <- name}
)
pacientesInnerJoin$ApellidosyNombre <- gsub(" ","",pacientesInnerJoin$ApellidosyNombre)


#Merge de los datos de optogait con los otros dos 
OptoDF <- merge(pacientesInnerJoin, nuevo_datos, by = c('ApellidosyNombre'))

#Datos que no coinciden para estudiar las pérdidas de pacientes y buscar una solución si fuera posible
datos_queNo_Coinciden <- merge(pacientesInnerJoin, nuevo_datos, by = c('ApellidosyNombre'), all = T)

datos_queNo_Coinciden <- datos_queNo_Coinciden[is.na(datos_queNo_Coinciden$Historial) | is.na(datos_queNo_Coinciden$`Paso.media`), ]
##Hay fallos de ortografía que me hacen eliminar varios pacientes ( que no son ni tildes ni mayúsculas, por ejemplo, una letra omitida)

```

Si ignoramos el peso, nº pie y altura:
```{r}
# #Junto las variables Nombre y Apellidos del anterior dataframe para poder unificarlo con el df de opto, le quito los espacios y me quedo con las tres primeras letras
# pacientesLeftJoin <- mutate(pacientesLeftJoin,ApellidosyNombre = paste(pacientesLeftJoin$Apellidos, pacientesLeftJoin$Nombre))[-c(1,2,3,4)]
# pacientesLeftJoin$ApellidosyNombre <- lapply(pacientesLeftJoin$ApellidosyNombre, function(x){ 
#     name <- ""
#     for (word in strsplit(x,split = " ")[[1]]){
#       name <- paste0(name,substr(word,start=1,stop=3))
#     }
#     x <- name}
# )
# pacientesLeftJoin$ApellidosyNombre <- gsub(" ","",pacientesLeftJoin$ApellidosyNombre)
# 
# 
# #Merge de los datos de optogait con los otros dos 
# OptoDF <- merge(pacientesLeftJoin, nuevo_datos, by = c('ApellidosyNombre'))
# 
# #Datos que no coinciden para estudiar las pérdidas de pacientes y buscar una solución si fuera posible
# datos_queNo_Coinciden <- merge(pacientesLeftJoin, nuevo_datos, by = c('ApellidosyNombre'), all = T)
# 
# datos_queNo_Coinciden <- datos_queNo_Coinciden[is.na(datos_queNo_Coinciden$Historial) | is.na(datos_queNo_Coinciden$`Paso.media`), ]
# ##Hay fallos de ortografía que me hacen eliminar varios pacientes ( que no son ni tildes ni mayúsculas, por ejemplo, una letra omitida)

```



Etiquetas en el historial:
```{r}

#Numerizo la salida:
#Fascitis: 1
#Esguince: 2
#Pie Plano: 3
#Pie Cavo: 4
#Aquiles: 5
#Síndrome de Predislocacion: 6
#Retropie Varo: 7
#Retropie Valgo: 8
#Otro: 9

OptoDF <- OptoDF %>%
  mutate(Patology = case_when(
    grepl("fasc",OptoDF$Historial,ignore.case=TRUE) ~ 1,
    grepl( "esguince",OptoDF$Historial,ignore.case=TRUE) ~ 2,
    grepl( "pie plano|plano|PP",OptoDF$Historial,ignore.case=TRUE) ~ 3,
    grepl( "pie cavo|cavo|PC|vavo",OptoDF$Historial,ignore.case=TRUE) ~ 4,
    grepl( "aquiles|aquilea",OptoDF$Historial,ignore.case=TRUE) ~ 5,
    grepl( "predislocacion|pred",OptoDF$Historial,ignore.case=TRUE) ~ 6,
    grepl( "varo",OptoDF$Historial,ignore.case=TRUE) ~ 7,
    grepl( "valgo",OptoDF$Historial,ignore.case=TRUE) ~ 8,
    
    TRUE ~ 9
  ), .before = 1)

#Anonimizo los datos
ID <- 1:nrow(OptoDF)
OptoDF <- cbind(ID,OptoDF)
PatologiaHistoria <- data.frame(Patology=OptoDF$Patology, Historia=OptoDF$Historial) #descomentar cuando se quiera hacer una comparación de las historias y la etiqueta definida
OptoDF <- subset(OptoDF,select = c(-Historial,-ApellidosyNombre))
OptoDF <- na.omit(OptoDF)
OptoDF$Peso.Kg.[which(OptoDF$Peso.Kg.==278)] <- 28 #Había una pesona de 278Kg que en realidad eran 28
OptoDF$Altura.cm.[which(OptoDF$Altura.cm.==283)] <- 183 #Había una pesona de 283cm que en realidad eran 183
write.csv2(OptoDF, "OptoDF.csv")
```

```{r}
PatologiaHistoria[PatologiaHistoria$Patology==1,]$Historia
```

Pie plano:87 -3
Pie cavo: 84 -4
Fascitis: 105 -1

Esguince: 26 -2
Aquiles: 19 -5
Sind. Predislocación: 17 -6

Unificado
Retropie Varo: 10 -7
Retropie Valgo: 91 -8

Otro: 219 (Eliminado)

```{r}
OptoDF <- read.csv2("OptoDF.csv",sep=";",dec=",",header = T, stringsAsFactors = T)[-1]
```


---------------FIN CONSTRUCCIÓN DATAFRAME--------------------------------------


------INICIO DE ESTUDIO DE VARIABLES Y ENTRENAMIENTO (incompleto por continuación en Python)--------

ANÁLISIS UNIVARIANTE

```{r}
data <- OptoDF[-1]
data$Patology <- as.factor(data$Patology)
#¿Están las variables distribuidas de forma normal?
#Veamos:

pValues <- sapply(data, function(x) shapiro.test(x)$p.value)
which(pValues>0.05)
pValuesnorm <- sapply(normData, function(x) shapiro.test(x)$p.value)#valores normalizados
which(pValuesnorm>0.05)

#Ninguna de las variables están distribuidas de forma normal

par(mfrow=c(10,6))
sapply(data, function(x) barplot(table(x),xlab="variable", ylab="Frecuencia"))

#Las distribuyo normalmente con la función NormaliseData

normData2 <- normalize(data[-1],method="range", range = c(0, 1)) #no normaliza
normData2 <- mutate(data[1],normData2)

#PCA, lasso, LDA,
#Juntar variables relacionadas

lambdas <- getLambda(data[-1],parallel = F)
normData <- normaliseData(data[-1],lambdas)
normData <- mutate(data[1],normData)

normpeso <- normaliseData(as.data.frame(data[2]), 0.69)
shapiro.test(normpeso$Peso.Kg.)

shapiro.test(normData$TContacto.media)
shapiro.test(data$TPaso.media)
# qqnorm(normData$TPaso.media)
# qqline(normData$TPaso.media)


barplot(table(cut(normData$TPaso.media,breaks=seq(min(normData$TPaso.media),max(normData$TPaso.media)+0.02, by=0.02))),main ="paso", ylab="Frecuencia", xlab = "paso")
barplot(table(cut(data$TPaso.media,breaks=seq(min(data$TPaso.media),max(data$TPaso.media)+0.01, by=0.02))),main ="paso", ylab="Frecuencia", xlab = "paso")

qqnorm(normData2$TPaso.media)
qqnorm(log(data$TPaso.media))
```
ANÁLISIS DE LAS VARIABLES

```{r}
library(glmnet)

model <- cv.glmnet (as.matrix (normData[-1]), as.matrix (normData[1]), type.measure = "class",family = 'multinomial', alpha=1 , nfolds=5)
```


ANÁLISIS BIVARIANTE
```{r}
summary(OptoDF$Patology)
res <- myAssoc2(`Peso.Kg.` ~ as.factor(Patology), data = OptoDF)
res$pvalue
```

```{r}
library("Hmisc")
library("corrplot")
correlation <- cor(OptoDF)[,"Patology"]
matrixs <- rcorr(as.matrix(OptoDF),type = "pearson")
matrixs$r[,"Patology"]
corrplot(matrixs$r)
correlation
```

MLR3

```{r}
library(mlr3learners)
library(mlr3viz)
library(mlr3tuning)
library(BBmisc)

data <- OptoDF[-1]
data$Patology <- as.factor(data$Patology)

#Normalizo los datos
normData <- normaliseData(data[-1],getLambda(data[-1], parallel = TRUE))
normData <- mutate(data[1],normData)

#creo un mlr3 task, que es el dataframe pero en un formato mlr3
task_Opto = as_task_classif(normData, target = "Patology", id="pieses")
#Hago las particiones
splits = partition(task_Opto)

#Elijo el algoritmo que voy a usar (GLMNET, modelos lineales generalizados) y como quiero la predicción si en probabilidades ("prob") o en clases ("response")
learner_rpart = lrn("classif.cv_glmnet", predict_type="response")


# param_set$set_values(<par1> = <value1>, ...)
learner_rpart$param_set

#creo el método de resample que voy a usar (repeated cross_validation)
resampling = rsmp("repeated_cv", folds=5, repeats=2)
#Lo aplico
rr = resample(task = task_Opto, learner = learner_rpart, resampling = resampling)
#Veo los resultados estadísticos
rr$aggregate(msr("classif.acc"))

#para ver los resultados en cada iteración
acc = rr$score(msr("classif.acc"))
acc[, .(iteration, classif.acc)]

as.data.table(mlr_measures)[c(3,10)]

measure <- msr("classif.acc")
measure$predict_type
```

GMLNET
```{r}

task_Opto = as_task_classif(normData, target = "Patology", id="pieses")
splits = partition(task_Opto)

learner_rpart = lrn("classif.cv_glmnet", predict_type="response")
learner_rpart$train(task_Opto,splits$train)
predictions = learner_rpart$predict(task_Opto, splits$test) # En mlr3 no se puede cambiar el parámetro s (es decir, el lambda que vamos a usar para las predicciones), supuestamente usa el óptimo por defecto, por eso deberíamos olvidarnos de tal cosa.
autoplot(predictions)

```

Pruebo quitando la clase "otro"
```{r}
#hago un df quitando valores de la clase 9 ("otro")
dataotro <-  slice_sample(normData[which(normData$Patology==9),],n=150)
dataotro <- anti_join(normData,dataotro)
table(dataotro$Patology)

task_Opto = as_task_classif(dataotro, target = "Patology", id="pieses")
splits = partition(task_Opto)

learner_rpart = lrn("classif.cv_glmnet", predict_type="response")
learner_rpart$train(task_Opto,splits$train)
predictions = learner_rpart$predict(task_Opto, splits$test) # En mlr3 no se puede cambiar el parámetro s (es decir, el lambda que vamos a usar para las predicciones), supuestamente usa el óptimo por defecto, por eso deberíamos olvidarnos de tal cosa.
autoplot(predictions)
```

Reducción de variables con glmnet
```{r}

selected_varaibles_GLMN <- learner_rpart$selected_features(learner_rpart$model$lambda.min)

#Creo un problema con las variables reducidas. Hn sido seleccionadas por glmnet justo encima. (no ha valio pa na)
GLMN_feature_reduced <- normData[, selected_varaibles_GLMN]
GLMN_feature_reduced <- mutate(data[1],GLMN_feature_reduced)


task2= as_task_classif(GLMN_feature_reduced, target="Patology", id="glmnred")
splis=partition(task2)
learner_rpart = lrn("classif.cv_glmnet", predict_type="response")
learner_rpart$train(task_Opto,splis$train)
predictions = learner_rpart$predict(task_Opto, splis$test) # En mlr3 no s epuede cambiar el parámetro s (es decir, el lambda que vamos a usar para las predicciones), supuestamente usa el óptimo por defecto, por eso deberíamos olvidarnos de tal cosa.
autoplot(predictions)

#no ha servio pa na
```


HIPERPARAMETRIZACIÓN
```{r}

normData <- normaliseData(data[-1],getLambda(data, parallel = TRUE))
normData <- mutate(data[1],normData)

resampling = rsmp("cv", folds=5)

measure=msr("classif.mauc_aunp") #La medida por la cual se va a hiperparametrizar (decidir qué parámetros son los buenos cuando esta medida sea la mejor)

#creo un mlr3 task, que es el dataframe pero en un formato mlr3
task_Opto = as_task_classif(normData, target = "Patology", id="pieses")

learner = lrn("classif.svm",
  cost  = to_tune(1e-1, 1e5),
  gamma = to_tune(1e-1, 1),
  predict_type  = "prob",
  type="C-classification",
  kernel = "radial"
              )


instance = ti(
  task=task_Opto,
  learner=learner,
  resampling=resampling,
  measures=measure,
  terminator = trm("none") #Uso trm none para hacer una búsqueda de hiperparámetros exhaustiva, que se para sola al ser un grid search.
)

# Ahora elegimos un método que hará la selección de hiperparámetros, (Random Search y Grid Search 
# buscan casi todas las posibilidades (Grid search busca todas) y después hay algoritmos más sofisticados que en función del anterior resultado, 
# varían los hiperparámetros de una manera u otra como Iterative Racing, 
# Covariance Matrix Adaptation... estos últimos son más sofisticados)

tuner = tnr("grid_search", resolution = 5, batch_size = 10) #Resolution es el nº de valores que se prueban por cada hiperparámetro y batch_size es cuántas configuraciones se evalúan al mismo tiempo

tuner$optimize(instance)

```

PCA
```{r}
library("mlr3pipelines")

task_Opto = as_task_classif(normData, target = "Patology", id="pieses")
#Para aplicar pca tengo que hacerlo con pipelines, creo un po
pca = po("pca") 
measure=msr("classif.mauc_aunp")

learnersd=lrn("classif.multinom")
learnersd$param_set
graph = pca %>>%
  po("learner",
    learner = lrn("classif.multinom",
  size  = to_tune(1, 20),
  decay = to_tune(1e-1, 10),
  predict_type  = "response",
  
              ))

resampling = rsmp("cv", folds=5)

learner = as_learner(graph)

instance = ti(
  task=task_Opto,
  learner=learner,
  resampling=resampling,
  measures=measure,
  terminator = trm("none") #Uso trm none para hacer una búsqueda de hiperparámetros exhaustiva, que se para sola al ser un grid search.
)

# Ahora elegimos un método que hará la selección de hiperparámetros, (Random Search y Grid Search 
# buscan casi todas las posibilidades (Grid search busca todas) y después hay algoritmos más sofisticados que en función del anterior resultado, 
# varían los hiperparámetros de una manera u otra como Iterative Racing, 
# Covariance Matrix Adaptation... estos últimos son más sofisticados)

tuner = tnr("grid_search", resolution = 5, batch_size = 10) #Resolution es el nº de valores que se prueban por cada hiperparámetro y batch_size es cuántas configuraciones se evalúan al mismo tiempo

tuner$optimize(instance)


```